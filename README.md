# DLD_dataset
The DLD_dataset makes use of Google landmark-v2. We organize 10 tasks, in a total of 200,000 images. We process each task with different image distortions. Each task is divided into training dataset and validation dataset. But due to the limit of file size in github, I have tried plenty of methods, but all failed to upload it...
